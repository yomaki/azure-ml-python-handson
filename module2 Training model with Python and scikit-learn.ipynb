{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5978a0ac",
   "metadata": {},
   "source": [
    "# Module2: Python と scikit-learn でのモデル学習とチューニング\n",
    "30分\n",
    "\n",
    "このモジュールでは、Python と Scikit Learn を使用して機械学習のモデルを学習していきます。Azure Machine Leraning 上ではコンピューティングインスタンスとコンピューティングクラスタを使いモデルの学習ができます。\n",
    "\n",
    "1. [Azure との接続](#Azure-との接続)\n",
    "    1. [Notebooks から Azure Machine Learning を始める](#Notebooks-から-Azure-Machine-Learning-を始める)\n",
    "    1. [Azure Machine Learning Python SDK](#Azure-Machine-Learning-Python-SDK)\n",
    "    1. [ワークスペースに接続](#ワークスペースに接続)\n",
    "    1. [ワークスペース内の Azure Machine Learning のリソースを確認する](#ワークスペース内の-Azure-Machine-Learning-のリソースを確認する)\n",
    "1. [コンピューティングインスタンス上でモデル学習](#コンピューティングインスタンス上でモデル学習)\n",
    "    1. [実験として学習スクリプトを実行する](#実験として学習スクリプトを実行する)\n",
    "    1. [学習済みモデルを登録する](#学習済みモデルを登録する)\n",
    "1. [コンピューティングクラスタ上で学習の並列実行](#コンピューティングクラスタ上で学習の並列実行)\n",
    "    1. [計算リソースの作成](#計算リソースの作成)\n",
    "    1. [ハイパーパラメータチューニングの実験を実行](#ハイパーパラメータチューニングの実験を実行)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1074655b",
   "metadata": {},
   "source": [
    "# Azure との接続\n",
    "## Notebooks から Azure Machine Learning を始める\n",
    "\n",
    "Azure Machine Learning は機械学習ソリューションを作成、管理するためのクラウドベースのサービスです。\n",
    "データサイエンティストが既存のデータ処理、モデル開発スキルやフレームワークを活用し、それらのワークロードをクラウドに拡張することをサポートするために設計されています。\n",
    "\n",
    "多くのデータサイエンスや機械学習の作業がこのように Notebook で実現します。(Notebook の説明の割愛します。)\n",
    "\n",
    "\n",
    "## Azure Machine Learning Python SDK\n",
    "多くの Python コードが Notebook で実行でき、必要な Python パッケージがインストールされた環境で実行されます。今回の場合は、Azure Machine Learning コンピューティングインスタンス上の *Conda* 環境の中で Notebook を実行します。 この環境はデフォルトでインストールされており、データサイエンティストが普段の業務で利用する一般的な Python パッケージも含まれています。あわせて皆さんの Azure Machine Learning ワークスペース内のリソースを使用するための Azure Machine Learning Python SDK もインストールされています。\n",
    "\n",
    "下記のセルを実行することで、**azureml-core** パッケージをインポートし、インストールされている SDK のバージョンを確認してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e28689",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "\n",
    "print(\"Ready to use Azure ML\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b190b6d2",
   "metadata": {},
   "source": [
    "## ワークスペースに接続\n",
    "\n",
    "全ての実験や関連するリソースはあなたの Azure Machine Learning ワークスペースの中で管理されています。作成済みのワークスペースに接続、あるいは Azure Machine Learning SDK を使って新しく作成することができます。\n",
    "\n",
    "一般的にワークスペースとの接続情報を JSON ファイルとして保管しておくことをお勧めします。これによって、Azure subcription ID などの詳細を記憶しておく必要もなく容易に接続することが可能です。JSON 設定ファイルは、Azure ポータル上のワークスペースのブレード、あるいは Azure Machine Learning スタジオのワークスペース詳細ペインからダウンロードすることもできます。しかしもしワークスペース内のコンピューティングインスタンスを使用されている場合は、設定ファイルは既に *root* にダウンロードされています。\n",
    "\n",
    "下記のコードでは設定ファイルを使ってワークスペースに接続します。\n",
    "\n",
    "> **注釈**: Notebook のセッションで初めてワークスペースに接続する際は、Azure にサインインするために以下の手順を求められるかもしれません。`https://microsoft.com/devicelogin`　へのリンクをクリックすし、自動的に生成されたコードを入力することでAzure にサインインします。無事 Azure にサインインした後、開かれているタブを閉じてこの Notebook に戻れます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cccd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, \"loaded\")\n",
    "\n",
    "!ls /config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32856b",
   "metadata": {},
   "source": [
    "## ワークスペース内の Azure Machine Learning のリソースを確認する\n",
    "\n",
    "これでワークスペースと接続できましたので、リソースを使って作業をしてみましょう。例えば以下のコードを使ってワークスペース内のコンピューティングリソースを列挙することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d255c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Compute Resources:\")\n",
    "for compute_name in ws.compute_targets:\n",
    "    compute = ws.compute_targets[compute_name]\n",
    "    print(\"\\t\", compute.name, ':', compute.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e41766",
   "metadata": {},
   "source": [
    "## 学習用のスクリプトを作成する\n",
    "\n",
    "ここでは Python スクリプトを用いて糖尿病のデータセットを基に機械学習のモデルを学習します。それではスクリプトとデータ用のフォルダを作成して初めていきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73579361",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "\n",
    "# Create a folder for the experiment files\n",
    "training_folder = 'diabetes-training'\n",
    "os.makedirs(training_folder, exist_ok=True)\n",
    "\n",
    "# Copy the data file into the experiment folder\n",
    "shutil.copy('data/diabetes.csv', os.path.join(training_folder, \"diabetes.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da547a6",
   "metadata": {},
   "source": [
    "学習用のスクリプトを作成しフォルダに保存する準備ができました。\n",
    "\n",
    "今回は学習の実験をより柔軟に実行できるように実装します。パラーメータをスクリプトに与えることで、設定を変えて同じスクリプトの学習実験を繰り返し実行できるようになります。ここではロジスティック回帰モデルを学習するらいに、正則化(regularization) の割合を表すハイパーパラメータを、スクリプトのパラメータとして与えます。\n",
    "\n",
    "> **注釈**: このコードはスクリプトを *作成* するものです。実行はされません！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99163f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $training_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import argparse\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Set regularization hyperparameter\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--reg_rate', type=float, dest='reg', default=0.01)\n",
    "args = parser.parse_args()\n",
    "reg = args.reg\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "# load the diabetes dataset\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a logistic regression model\n",
    "print('Training a logistic regression model with regularization rate of', reg)\n",
    "run.log('Regularization Rate',  np.float(reg))\n",
    "model = LogisticRegression(C=1/reg, solver=\"liblinear\").fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "159585af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力されたスクリプトを確認\n",
    "!head $training_folder/diabetes_training.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b6a7f9",
   "metadata": {},
   "source": [
    "# コンピューティングインスタンス上でモデル学習\n",
    "## 実験として学習スクリプトを実行する\n",
    "\n",
    "これで実験としてスクリプトを実行する準備が整いました。デフォルトの環境には **scikit-learn** のパッケージがインストールされておらず、明示的に設定する必要がありますのでご注意下さい。 *condad* 環境は初めて環境を実行する際にオンデマンドで構築され、以降の実行時には同じ設定でキャッシュされています。そのため初回実行時のみ時間がかかるはずです。\n",
    "\n",
    "モデルのハイパーパラメータによって結果がどのように変化する確認できるよう、２種類の設定オブジェクトを準備しておきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f628e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "sklearn_env = Environment(\"sklearn-env\")\n",
    "\n",
    "# Ensure the required packages are installed (we need pip, scikit-learn and Azure ML defaults)\n",
    "packages = CondaDependencies.create(conda_packages=['pip', 'scikit-learn'],\n",
    "                                    pip_packages=['azureml-defaults'])\n",
    "sklearn_env.python.conda_dependencies = packages\n",
    "\n",
    "# Create a script config1\n",
    "script_config1 = ScriptRunConfig(source_directory=training_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                arguments = ['--reg_rate', 0.1],\n",
    "                                environment=sklearn_env) \n",
    "\n",
    "# Create a script config2\n",
    "script_config2 = ScriptRunConfig(source_directory=training_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                arguments = ['--reg_rate', 10],\n",
    "                                environment=sklearn_env)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e32cf7",
   "metadata": {},
   "source": [
    "準備が整いましたので、実行用のオブジェクトを **Experiment** から生成し、以下のように実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663216b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the experiment run\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config1)\n",
    "\n",
    "# Show the running experiment run in the notebook widget\n",
    "RunDetails(run).show()\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1887919",
   "metadata": {},
   "source": [
    "**Run** オブジェクトから指標や出力が取り出せます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82360c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get logged metrics and files\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6785fd",
   "metadata": {},
   "source": [
    "それではもう一方の設定 *script_config2* を使って実行して比較してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a28dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# submit the experiment run\n",
    "experiment_name = 'mslearn-train-diabetes'\n",
    "experiment = Experiment(workspace=ws, name=experiment_name)\n",
    "run = experiment.submit(config=script_config2)\n",
    "\n",
    "# Show the running experiment run in the notebook widget\n",
    "RunDetails(run).show()\n",
    "\n",
    "# Block until the experiment run has completed\n",
    "run.wait_for_completion()\n",
    "\n",
    "# Get logged metrics and files\n",
    "metrics = run.get_metrics()\n",
    "for key in metrics.keys():\n",
    "        print(key, metrics.get(key))\n",
    "print('\\n')\n",
    "for file in run.get_file_names():\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40652a72",
   "metadata": {},
   "source": [
    "## 学習済みモデルを登録する\n",
    "\n",
    "実験の出力には学習済みモデルのファイル(**diabetes_model.pkl**) も含まれています。このモデルを Azure Machine Learning ワークスペースに登録することで、モデルのバージョンを追跡したり後から取り出すことも可能になります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e236bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register the model\n",
    "run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                   tags={'Training context':'Parameterized script'},\n",
    "                   properties={'AUC': run.get_metrics()['AUC'], 'Accuracy': run.get_metrics()['Accuracy']})\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129e6116",
   "metadata": {},
   "source": [
    "## ハイパーパラメータのチューニング\n",
    "\n",
    "多くの機械学習のアルゴリズムはハイパーパラメータ(学習に影響するパラメータ値だが、学習データ自体から推定しないもの) を必要とします。例えばロジスティック回帰モデルを学習する場合は *regularization rate* というハイパーパラメータを使ってモデルのバイアスを軽減することができます。あるいは畳み込みニューラルネットワーク(CNN) の例だと、*learning rate* と*batch size* によって重み付けやミニバッチで処理するデータのサイズを制御することができます。ハイパーパラメータの決定はモデル学習のパフォーマンス、モデルの学習時間に強く影響します。一般的には複数の候補の組み合わせを試すことで適切な設定値を探します。\n",
    "\n",
    "今回は2つのハイパーパラメータを想定し分類モデルを学習します。しかし、この原理原則は Azure Machine Learning を用いたあらゆるモデル学習において適用することが可能です。また、より大規模なハイパーパラメータチューニングを想定し、コンピューティングクラスタを使った並列の実験を実行します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58deb256",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = 'diabetes_training-hyperdrive'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print('Folder ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11d50b7",
   "metadata": {},
   "source": [
    "それではモデルを学習するためのスクリプトを作成します。この例でいは、*Gradient Boosting* アルゴリズムを採用し、分類モデルを学習します。学習用のスクリプトには以下の要件を満たす必要があります。\n",
    "\n",
    "- 最適化したいそれぞれのハイパーパラメータを引数に持つ(今回は*learning rate*とアルゴリズムの*estimator*の数です)\n",
    "- 最適化するための評価指標をログとして残すように実装(今回は AUC と　accuracy の両方を記録し、モデル選定の際にどちらも考慮できるようにしています)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6a8fa1",
   "metadata": {},
   "source": [
    "## データ準備\n",
    "\n",
    "この実験では糖尿妙患者の詳細が含まれたデータセットを使います。下のセルを実行し、データセットを作成します。(既に存在している場合、既存のバージョンが使用されます)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20059d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12d2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse, joblib, os\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Input dataset\n",
    "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
    "\n",
    "# Hyperparameters\n",
    "parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\n",
    "parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\n",
    "\n",
    "# Add arguments to args collection\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Log Hyperparameter values\n",
    "run.log('learning_rate',  np.float(args.learning_rate))\n",
    "run.log('n_estimators',  np.int(args.n_estimators))\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['training_data'].to_pandas_dataframe() # Get the training data from the estimator input\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a Gradient Boosting classification model with the specified hyperparameters\n",
    "print('Training a classification model')\n",
    "model = GradientBoostingClassifier(learning_rate=args.learning_rate,\n",
    "                                   n_estimators=args.n_estimators).fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the model in the run outputs\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea2154a",
   "metadata": {},
   "source": [
    "# コンピューティングクラスタ上で学習の並列実行\n",
    "## 計算リソースの作成\n",
    "\n",
    "ハイパーパラメータのチューニングでは、異なる値の組み合わせによる複数の実験を繰り返し、パフォーマンス指標を比較します。効率的に達成するため、オンデマンドのクラウドコンピューティングの利点を活かしてクラスターを作成します。つまり複数の学習を並列実行させられます。\n",
    "\n",
    "後述のコードで Azure Machine Learning コンピューティングクラスタを指定します。(まだ作成していなければ、新たに作成します)\n",
    "\n",
    "> **重要**: 下記のコードを実行する前に、 *your-compute-cluster* を任意のコンピューティングクラスタ名に変更して下さい。クラスター名はグローバルでユニークな必要があり、文字数を2-16の範囲で指定してください。有効な文字は英数字とハイフンです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516fbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\" #cc-ym210625\n",
    "cluster_name = \"cc-ym210625\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_DS3_v2', max_nodes=10)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba7cab",
   "metadata": {},
   "source": [
    "## ハイパーパラメータチューニングの実験を実行\n",
    "\n",
    "Azure Machine Learning は*hyperdrive*と言うハイパーパラメータチューニングのための機能があります。この実験では子の実行が発行され、それぞれ異なるハイパーパラメータの組み合わせで実行されます。最良のモデルを生成した実行(任意のパフォーマンス指標によって選定される)は特定でき、登録やデプロイのために学習済みモデルが選択されます。\n",
    "The run producing the best model (as determined by the logged target performance metric for which you want to optimize) can be identified, and its trained model selected for registration and deployment.\n",
    "\n",
    "> **注釈**: この例では early stopping policy は明記しません。(後略。詳細は原文をご覧ください)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492adc75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "#from azureml.core.conda_dependencies import CondaDependencies\n",
    "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
    "#from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "sklearn_env = Environment(\"sklearn-env\")\n",
    "\n",
    "# Ensure the required packages are installed (we need scikit-learn, Azure ML defaults, and Azure ML dataprep)\n",
    "packages = CondaDependencies.create(conda_packages=['scikit-learn','pip'],\n",
    "                                    pip_packages=['azureml-defaults','azureml-dataprep[pandas]'])\n",
    "sklearn_env.python.conda_dependencies = packages\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
    "                                environment=sklearn_env,\n",
    "                                compute_target = training_cluster)\n",
    "\n",
    "# Sample a range of parameter values\n",
    "params = GridParameterSampling(\n",
    "    {\n",
    "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
    "        '--learning_rate': choice(0.01, 0.1, 1.0),\n",
    "        '--n_estimators' : choice(10, 100)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure hyperdrive settings\n",
    "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
    "                          hyperparameter_sampling=params, \n",
    "                          policy=None, # No early stopping policy\n",
    "                          primary_metric_name='AUC', # Find the highest AUC metric\n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=6, # Restict the experiment to 6 iterations\n",
    "                          max_concurrent_runs=6) # Run up to 2 iterations in parallel\n",
    "\n",
    "# Run the experiment\n",
    "experiment = Experiment(workspace=ws, name='mslearn-diabetes-hyperdrive')\n",
    "run = experiment.submit(config=hyperdrive)\n",
    "\n",
    "# Show the status in the notebook as the experiment runs\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8d985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
