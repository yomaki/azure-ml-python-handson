{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module3: 様々な環境へのデプロイ\n",
    "30分\n",
    "\n",
    "モジュール2では、いくつかのパターンでモデルの学習を実演しました。モジュール３では学習済みモデルを本番環境にデプロイする、と言うシナリオを意識します。デプロイ先にはいくつかの選択肢がありますが、[ローカル](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-deploy-local-container-notebook-vm)、[Azure Kubernetes Service](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-deploy-azure-kubernetes-service?tabs=python)、[Azure Container Instances](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-deploy-azure-container-instance)などがその一例です。\n",
    "今回は Azure Container Instances(ACI)　と Azure Kubernetes Serivice(AKS) へのデプロイを実演します。\n",
    "\n",
    "\n",
    "1. [ACI を使ってリアルタイム推論サービスを作成する](#ACI-を使ってリアルタイム推論サービスを作成する)\n",
    "    1. [ワークスペースへの接続](#ワークスペースへの接続)\n",
    "    1. [モデルをWebサービスとしてデプロイ](#モデルを-Web-サービスとしてデプロイ)\n",
    "    1. [モデルを Web サービスとしてデプロイ](#モデルを-Web-サービスとしてデプロイ)\n",
    "    1. [Web サービスをコール](#Web-サービスをコール)\n",
    "    1. [サービスの削除](#サービスの削除)\n",
    "1. [AKS を使って推論クラスタを作成](#AKS-を使って推論クラスタを作成)\n",
    "    1. [推論クラスタの作成](#推論クラスタの作成)\n",
    "    1. [推論クラスタにデプロイ](#推論クラスタにデプロイ)\n",
    "    1. [AKS にリクエスト](#AKS-にリクエスト)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACI を使ってリアルタイム推論サービスを作成する\n",
    "\n",
    "予測モデルを学習すると、クライアントから新しいデータに対する予測値を取得するようなリアルタイムサービスをデプロイすることができます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ワークスペースへの接続\n",
    "\n",
    "まずはワークスペースに接続します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを Web サービスとしてデプロイ\n",
    "\n",
    "前のモジュールで、糖尿病かどうかの尤もらしさを基に患者を分類するモデルを学習し登録しています。医療現場の特定のシナリオにおいて、このモデルは本番環境で使えるかもしれません。本番環境を想定し、Web サービスとしてデプロイします。\n",
    "\n",
    "まずはワークスペースにどのようなモデルが登録されているか確認しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "それではデプロイしたいモデルを取得しましょう。モデル名をしてした際、デフォルトでは最新のバージョンが返ってきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ws.models['diabetes_model']\n",
    "print(model.name, 'version', model.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得したモデルをホストする Web サービスを作成します。これにはいくつかのスクリプトと設定ファイルが必要ですので、フォルダを作成し準備していきます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_name = 'diabetes_service'\n",
    "\n",
    "# Create a folder for the web service files\n",
    "experiment_folder = './' + folder_name\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print(folder_name, 'folder created.')\n",
    "\n",
    "# Set path for scoring script\n",
    "script_file = os.path.join(experiment_folder,\"score_diabetes.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "モデルをデプロイする Web サービスでは、入力データの読み込み、ワークスペースからモデルの取得、そして予測値を返すための Python コードが必要です。以下のように Web サービスにデプロイされる *entry script* (あるいは *scoring script*) に保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $script_file\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "from azureml.core.model import Model\n",
    "\n",
    "# Called when the service is loaded\n",
    "def init():\n",
    "    global model\n",
    "    # Get the path to the deployed model file and load it\n",
    "    model_path = Model.get_model_path('diabetes_model')\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "# Called when a request is received\n",
    "def run(raw_data):\n",
    "    # Get the input data as a numpy array\n",
    "    data = np.array(json.loads(raw_data)['data'])\n",
    "    # Get a prediction from the model\n",
    "    predictions = model.predict(data)\n",
    "    # Get the corresponding classname for each prediction (0 or 1)\n",
    "    classnames = ['not-diabetic', 'diabetic']\n",
    "    predicted_classes = []\n",
    "    for prediction in predictions:\n",
    "        predicted_classes.append(classnames[prediction])\n",
    "    # Return the predictions as JSON\n",
    "    return json.dumps(predicted_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web サービスはコンテナの中にホストされ、コンテナは初期化の際に　Python の必要なパッケージをインストールする必要があります。今回の推論コードでは **scikit-learn** が必要で、この情報を YAML ファイルでコンテナに与えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.conda_dependencies import CondaDependencies \n",
    "\n",
    "# Add the dependencies for our model (AzureML defaults is already included)\n",
    "myenv = CondaDependencies()\n",
    "myenv.add_conda_package('scikit-learn')\n",
    "\n",
    "# Save the environment config as a .yml file\n",
    "env_file = os.path.join(experiment_folder,\"diabetes_env.yml\")\n",
    "with open(env_file,\"w\") as f:\n",
    "    f.write(myenv.serialize_to_string())\n",
    "print(\"Saved dependency info in\", env_file)\n",
    "\n",
    "# Print the .yml file\n",
    "with open(env_file,\"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上でデプロイの準備が完了です。それでは **diabetes-service** と言うサービス名のコンテナをデプロイしましょう。デプロイのプロセスは以下の通りです。\n",
    "\n",
    "1. 推論設定(モデルをロードし使用するための推論スクリプト、環境ファイル)を定義\n",
    "2. デプロイ定義(ホストされたサービスの実行環境の定義。ここではAzure Container Instance)\n",
    "3. モデルを Web サービスとしてデプロイ\n",
    "4. デプロイされたサービスの状態を確認\n",
    "\n",
    "> **詳細**: モデルのデプロイと実行環境のオプションについては [ドキュメント](https://docs.microsoft.com/azure/machine-learning/how-to-deploy-and-where)をご覧ください。\n",
    "\n",
    "コンテナイメージを作成する手続きが最初に発生するため、デプロイには少し時間がかかります。作成されたイメージを基に Web サービスが作成されます。デプロイに成功すると、ステータスが **Healthy** と表示されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "# Configure the scoring environment\n",
    "inference_config = InferenceConfig(runtime= \"python\",\n",
    "                                   entry_script=script_file,\n",
    "                                   conda_file=env_file)\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "\n",
    "service_name = \"diabetes-service\"\n",
    "\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config)\n",
    "\n",
    "service.wait_for_deployment(True)\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "何事もなく **Healthy** と表示されているといいのですが、もし失敗している場合は以下のコードでトラブルシューティングのためのログが表示できます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service.get_logs())\n",
    "\n",
    "# If you need to make a change and redeploy, you may need to delete unhealthy service using the following code:\n",
    "#service.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Azure Machine Learning Studio](https://ml.azure.com) のワークスペースからエンドポイントのページを開き、デプロイされているサービスを表示してみましょう。\n",
    "\n",
    "下記のコードからもワークスペース内の Web サービスを取得することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for webservice_name in ws.webservices:\n",
    "    print(webservice_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web サービスをコール\n",
    "\n",
    "デプロイされたサービスを、クライアントアプリケーションからコールすることができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22]]\n",
    "print ('Patient: {}'.format(x_new[0]))\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data (the web service will also accept the data in binary format)\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted class - it'll be the first (and only) one.\n",
    "predicted_classes = json.loads(predictions)\n",
    "print(predicted_classes[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "複数行のデータを推論することも可能です。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This time our input is an array of two feature arrays\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array or arrays to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Call the web service, passing the input data\n",
    "predictions = service.run(input_data = input_json)\n",
    "\n",
    "# Get the predicted classes.\n",
    "predicted_classes = json.loads(predictions)\n",
    "   \n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上記のコードでは Azure Machine Learning SDK を使ってコンテナ化された Web サービスに接続し、学習済みモデルで予測値を生成しています。本番環境では、モデルは Azure Machine Learning SDK を使っていないビジネスアプリケーションから利用されるより、単純に HTTP リクエストで Web サービスを利用する方が一般的でしょう。\n",
    "\n",
    "それではアプリケーションのアクセス先となる URL を定義しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = service.scoring_uri\n",
    "print(endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これでエンドポイントの URL が取得できましたので、HTTP リクエストを作成し、患者データを JSON 形式で送信し、予測カテゴリを取得します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "# Convert the array to a serializable list in a JSON document\n",
    "input_json = json.dumps({\"data\": x_new})\n",
    "\n",
    "# Set the content type\n",
    "headers = { 'Content-Type':'application/json' }\n",
    "\n",
    "predictions = requests.post(endpoint, input_json, headers = headers)\n",
    "predicted_classes = json.loads(predictions.json())\n",
    "\n",
    "for i in range(len(x_new)):\n",
    "    print (\"Patient {}\".format(x_new[i]), predicted_classes[i] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これまでの処理で、認証を必要としない Web サービスを Azure Container Instance としてデプロイしました。開発・検証の環境であれば十分ですが、本番環境では Azure Kubernetes Services (AKS) クラスタへのデプロイとトークンベースの認証を検討すべきです。これは **Authorization** のヘッダーを含む　REST リクエストが要求されます。\n",
    "\n",
    "## サービスの削除\n",
    "\n",
    "サービスがもう必要ない状況になれば、不要な費用を避けるためにも削除しておくことを推奨します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "print ('Service deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AKS を使って推論クラスタを作成\n",
    "\n",
    "最後に AKS を使った推論クラスタへのデプロイを実演します。\n",
    "前述の通り、本番環境ではリクエスト数に対してスケールさせたり、認証を意識した設計が重要です。\n",
    "\n",
    "## 推論クラスタの作成\n",
    "まずはデプロイするためのクラスタを作成します。今回は Azure Machine Learning Studio から AKS を作成してみます。\n",
    "コンピューティングから推論クラスタを選び、新規を選びます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 推論クラスタにデプロイ\n",
    "AKS にデプロイするために必要なコンピューティングリソースを記述したデプロイ構成を作成します。[ドキュメント](https://docs.microsoft.com/ja-jp/azure/machine-learning/how-to-deploy-azure-kubernetes-service?tabs=python#deploy-to-aks)のサンプルコードを流用しています。\n",
    "デプロイの設定ではコア数、メモリ量が指定されていますが、これらは Web サービスに割り当てられるリソースを意味しています。\n",
    "\n",
    "作成が成功したら下記の *your-compute-cluster* をクラスタ名を置き換えてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AksWebservice, Webservice\n",
    "from azureml.core.compute import AksCompute\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "service_name = \"aks-service\"\n",
    "\n",
    "aks_target = AksCompute(ws, cluster_name)\n",
    "# If deploying to a cluster configured for dev/test, ensure that it was created with enough\n",
    "# cores and memory to handle this deployment configuration. Note that memory is also used by\n",
    "# things such as dependencies and AML components.\n",
    "deployment_config = AksWebservice.deploy_configuration(cpu_cores = 1, memory_gb = 1)\n",
    "service = Model.deploy(ws, service_name, [model], inference_config, deployment_config, aks_target)\n",
    "service.wait_for_deployment(show_output = True)\n",
    "print(service.state)\n",
    "print(service.get_logs())\n",
    "print(service.state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "デプロイが成功していれば、**Healthy** と表示されるはずです。\n",
    "\n",
    "## AKS にリクエスト\n",
    "Azure Machine Learning Studio のエンドポイントに、デプロイされているサービスの一覧が表示されます。今回デプロイしたサービスを開くと、使用というタブから URL や認証用のキーが確認できます。以下のようなサンプルコードでアクセスすることができます。(一部修正しています)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import os\n",
    "import ssl\n",
    "\n",
    "def allowSelfSignedHttps(allowed):\n",
    "    # bypass the server certificate verification on client side\n",
    "    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):\n",
    "        ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.\n",
    "\n",
    "# Request data goes here\n",
    "x_new = [[2,180,74,24,21,23.9091702,1.488172308,22],\n",
    "         [0,148,58,11,179,39.19207553,0.160829008,45]]\n",
    "\n",
    "#data = json.dumps({\"data\": x_new})\n",
    "data = {\"data\": x_new}\n",
    "\n",
    "body = str.encode(json.dumps(data))\n",
    "\n",
    "url = service.scoring_uri\n",
    "api_key, _ = service.get_keys()\n",
    "headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key)}\n",
    "\n",
    "req = urllib.request.Request(url, body, headers)\n",
    "\n",
    "try:\n",
    "    response = urllib.request.urlopen(req)\n",
    "\n",
    "    result = response.read()\n",
    "    print(result)\n",
    "except urllib.error.HTTPError as error:\n",
    "    print(\"The request failed with status code: \" + str(error.code))\n",
    "\n",
    "    # Print the headers - they include the requert ID and the timestamp, whAKS にリクエストich are useful for debugging the failure\n",
    "    print(error.info())\n",
    "    print(json.loads(error.read().decode(\"utf8\", 'ignore')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure Container Instance と同様の結果が得られたことが確認できました。\n",
    "ACI の例と同様、サービスが不要になれば削除しておきましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service.delete()\n",
    "print ('Service deleted.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "また、AKS 自体は削除されていないので、クラスタ自体が不要な場合は忘れずに削除しましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}